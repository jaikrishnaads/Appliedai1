{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfde0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started...\n",
      "\n",
      "==================================================\n",
      "FIRST EPOCH\n",
      "==================================================\n",
      "Output: 0.530462\n",
      "Error: 0.469538\n",
      "\n",
      "Updated W1:\n",
      "  W1_11: 0.309964\n",
      "  W1_12: 0.091697\n",
      "  W1_13: -0.209964\n",
      "  W1_21: -0.190036\n",
      "  W1_22: 0.391697\n",
      "  W1_23: 0.290036\n",
      "  W1_31: 0.200000\n",
      "  W1_32: -0.300000\n",
      "  W1_33: 0.100000\n",
      "  W1_41: 0.109964\n",
      "  W1_42: 0.391697\n",
      "  W1_43: -0.109964\n",
      "Updated b1:\n",
      "  b1_1: 0.209964\n",
      "  b1_2: 0.091697\n",
      "  b1_3: 0.040036\n",
      "Updated W2:\n",
      "  W2_11: 0.306643\n",
      "  W2_12: -0.209964\n",
      "  W2_21: 0.116607\n",
      "  W2_22: 0.375090\n",
      "  W2_31: -0.299170\n",
      "  W2_32: 0.198754\n",
      "Updated b2:\n",
      "  b2_1: 0.116607\n",
      "  b2_2: -0.224910\n",
      "Updated V (Output weights):\n",
      "  V1: 0.225325\n",
      "  V2: -0.289206\n",
      "Updated C (Output bias):\n",
      "  C: 0.183034\n",
      "\n",
      "==================================================\n",
      "TRAINING COMPLETED\n",
      "==================================================\n",
      "Total Epochs: 17686\n",
      "Final Output: 0.999000\n",
      "Final Error: 0.001000\n",
      "\n",
      "Final W1:\n",
      "  W1_11: 0.632159\n",
      "  W1_12: 0.346731\n",
      "  W1_13: -0.219515\n",
      "  W1_21: 0.132159\n",
      "  W1_22: 0.646731\n",
      "  W1_23: 0.280485\n",
      "  W1_31: 0.200000\n",
      "  W1_32: -0.300000\n",
      "  W1_33: 0.100000\n",
      "  W1_41: 0.432159\n",
      "  W1_42: 0.646731\n",
      "  W1_43: -0.119515\n",
      "Final b1:\n",
      "  b1_1: 0.532159\n",
      "  b1_2: 0.346731\n",
      "  b1_3: 0.030485\n",
      "Final W2:\n",
      "  W2_11: 0.883399\n",
      "  W2_12: -0.235293\n",
      "  W2_21: 0.894389\n",
      "  W2_22: 0.334882\n",
      "  W2_31: -0.298995\n",
      "  W2_32: 0.198530\n",
      "Final b2:\n",
      "  b2_1: 0.711056\n",
      "  b2_2: -0.258648\n",
      "Final V (Output weights):\n",
      "  V1: 1.420307\n",
      "  V2: -0.285578\n",
      "Final C (Output bias):\n",
      "  C: 1.203979\n",
      "\n",
      "==================================================\n",
      "PREDICTION TEST\n",
      "==================================================\n",
      "Input: [1 1 0 1]\n",
      "Predicted Output: 0.999000\n",
      "Target Output: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ActivationFunctions:\n",
    "    \"\"\"Collection of activation functions and their derivatives\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-np.clip(x, -500, 500)))\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid_derivative(y):\n",
    "        return y * (1 - y)\n",
    "    \n",
    "    @staticmethod\n",
    "    def relu(x):\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    @staticmethod\n",
    "    def relu_derivative(x):\n",
    "        return (x > 0).astype(float)\n",
    "    \n",
    "    @staticmethod\n",
    "    def leaky_relu(x, alpha=0.01):\n",
    "        return np.where(x > 0, x, alpha * x)\n",
    "    \n",
    "    @staticmethod\n",
    "    def leaky_relu_derivative(x, alpha=0.01):\n",
    "        return np.where(x > 0, 1, alpha)\n",
    "    \n",
    "    @staticmethod\n",
    "    def tanh(x):\n",
    "        return np.tanh(x)\n",
    "    \n",
    "    @staticmethod\n",
    "    def tanh_derivative(x):\n",
    "        return 1 - np.tanh(x)**2\n",
    "    \n",
    "    @staticmethod\n",
    "    def swish(x):\n",
    "        return x / (1 + np.exp(-np.clip(x, -500, 500)))\n",
    "    \n",
    "    @staticmethod\n",
    "    def swish_derivative(x):\n",
    "        sig = 1 / (1 + np.exp(-np.clip(x, -500, 500)))\n",
    "        return sig + x * sig * (1 - sig)\n",
    "    \n",
    "    @staticmethod\n",
    "    def softmax(x):\n",
    "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "    \n",
    "    @staticmethod\n",
    "    def softmax_derivative(softmax_output):\n",
    "        s = softmax_output.reshape(-1, 1)\n",
    "        return np.diagflat(s) - np.dot(s, s.T)\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    \"\"\"Simple feedforward neural network with backpropagation\"\"\"\n",
    "    \n",
    "    def __init__(self, learning_rate=0.71, error_threshold=0.001):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.error_threshold = error_threshold\n",
    "        self.activation = ActivationFunctions()\n",
    "        \n",
    "        # Initialize weights and biases\n",
    "        self.W1 = np.array([\n",
    "            [0.3, 0.1, -0.2],\n",
    "            [-0.2, 0.4, 0.3],\n",
    "            [0.2, -0.3, 0.1],\n",
    "            [0.1, 0.4, -0.1]\n",
    "        ])\n",
    "        self.b1 = np.array([[0.2, 0.1, 0.05]])\n",
    "        \n",
    "        self.W2 = np.array([\n",
    "            [0.3, -0.2],\n",
    "            [0.1, 0.4],\n",
    "            [-0.3, 0.2]\n",
    "        ])\n",
    "        self.b2 = np.array([[0.1, -0.2]])\n",
    "        \n",
    "        self.V = np.array([[0.2], [-0.3]])\n",
    "        self.C = np.array([[0.1]])\n",
    "        \n",
    "        self.epoch_count = 0\n",
    "        self.first_epoch_printed = False\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"Forward propagation through the network\"\"\"\n",
    "        # First hidden layer\n",
    "        self.z1 = np.dot(X, self.W1) + self.b1\n",
    "        self.h1 = self.activation.relu(self.z1)\n",
    "        \n",
    "        # Second hidden layer\n",
    "        self.z2 = np.dot(self.h1, self.W2) + self.b2\n",
    "        self.h2 = self.activation.relu(self.z2)\n",
    "        \n",
    "        # Output layer\n",
    "        self.u = np.dot(self.h2, self.V) + self.C\n",
    "        self.output = self.activation.sigmoid(self.u)\n",
    "        \n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, X, Y):\n",
    "        \"\"\"Backpropagation to compute gradients\"\"\"\n",
    "        # Calculate error\n",
    "        error = Y - self.output\n",
    "        \n",
    "        # Output layer gradients\n",
    "        delta_output = error * self.activation.sigmoid_derivative(self.output)\n",
    "        \n",
    "        # Second hidden layer gradients\n",
    "        delta_h2 = delta_output.dot(self.V.T) * self.activation.relu_derivative(self.z2)\n",
    "        \n",
    "        # First hidden layer gradients\n",
    "        delta_h1 = delta_h2.dot(self.W2.T) * self.activation.relu_derivative(self.z1)\n",
    "        \n",
    "        # Update weights and biases\n",
    "        self.V += self.learning_rate * self.h2.T.dot(delta_output)\n",
    "        self.C += self.learning_rate * delta_output\n",
    "        \n",
    "        self.W2 += self.learning_rate * self.h1.T.dot(delta_h2)\n",
    "        self.b2 += self.learning_rate * delta_h2\n",
    "        \n",
    "        self.W1 += self.learning_rate * X.T.dot(delta_h1)\n",
    "        self.b1 += self.learning_rate * delta_h1\n",
    "        \n",
    "        return error\n",
    "    \n",
    "    def print_weights(self, prefix=\"\"):\n",
    "        \"\"\"Print current weights and biases\"\"\"\n",
    "        print(f\"\\n{prefix}W1:\")\n",
    "        for i in range(self.W1.shape[0]):\n",
    "            for j in range(self.W1.shape[1]):\n",
    "                print(f\"  W1_{i+1}{j+1}: {self.W1[i, j]:.6f}\")\n",
    "        \n",
    "        print(f\"{prefix}b1:\")\n",
    "        for j in range(self.b1.shape[1]):\n",
    "            print(f\"  b1_{j+1}: {self.b1[0, j]:.6f}\")\n",
    "        \n",
    "        print(f\"{prefix}W2:\")\n",
    "        for i in range(self.W2.shape[0]):\n",
    "            for j in range(self.W2.shape[1]):\n",
    "                print(f\"  W2_{i+1}{j+1}: {self.W2[i, j]:.6f}\")\n",
    "        \n",
    "        print(f\"{prefix}b2:\")\n",
    "        for j in range(self.b2.shape[1]):\n",
    "            print(f\"  b2_{j+1}: {self.b2[0, j]:.6f}\")\n",
    "        \n",
    "        print(f\"{prefix}V (Output weights):\")\n",
    "        for i in range(self.V.shape[0]):\n",
    "            print(f\"  V{i+1}: {self.V[i, 0]:.6f}\")\n",
    "        \n",
    "        print(f\"{prefix}C (Output bias):\")\n",
    "        print(f\"  C: {self.C[0, 0]:.6f}\")\n",
    "    \n",
    "    def train(self, X, Y, max_epochs=100000):\n",
    "        \"\"\"Train the neural network\"\"\"\n",
    "        print(\"Training started...\")\n",
    "        \n",
    "        while self.epoch_count < max_epochs:\n",
    "            self.epoch_count += 1\n",
    "            \n",
    "            # Forward and backward pass\n",
    "            output = self.forward(X)\n",
    "            error = self.backward(X, Y)\n",
    "            \n",
    "            # Print first epoch details\n",
    "            if not self.first_epoch_printed:\n",
    "                print(\"\\n\" + \"=\"*50)\n",
    "                print(\"FIRST EPOCH\")\n",
    "                print(\"=\"*50)\n",
    "                print(f\"Output: {output.item():.6f}\")\n",
    "                print(f\"Error: {error.item():.6f}\")\n",
    "                self.print_weights(\"Updated \")\n",
    "                self.first_epoch_printed = True\n",
    "            \n",
    "            # Check convergence\n",
    "            if abs(error.item()) < self.error_threshold:\n",
    "                print(\"\\n\" + \"=\"*50)\n",
    "                print(\"TRAINING COMPLETED\")\n",
    "                print(\"=\"*50)\n",
    "                print(f\"Total Epochs: {self.epoch_count}\")\n",
    "                print(f\"Final Output: {output.item():.6f}\")\n",
    "                print(f\"Final Error: {error.item():.6f}\")\n",
    "                self.print_weights(\"Final \")\n",
    "                break\n",
    "        \n",
    "        if self.epoch_count >= max_epochs:\n",
    "            print(f\"\\nReached maximum epochs ({max_epochs}) without convergence\")\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions on new data\"\"\"\n",
    "        return self.forward(X)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    # Training data\n",
    "    X = np.array([[1, 1, 0, 1]])\n",
    "    Y = np.array([[1]])\n",
    "    \n",
    "    # Create and train network\n",
    "    nn = NeuralNetwork(learning_rate=0.71, error_threshold=0.001)\n",
    "    nn.train(X, Y)\n",
    "    \n",
    "    # Test prediction\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"PREDICTION TEST\")\n",
    "    print(\"=\"*50)\n",
    "    prediction = nn.predict(X)\n",
    "    print(f\"Input: {X[0]}\")\n",
    "    print(f\"Predicted Output: {prediction.item():.6f}\")\n",
    "    print(f\"Target Output: {Y.item()}\")\n",
    "\n",
    "\n",
    "# Avoid auto-running the demo when the file is loaded inside a notebook\n",
    "if __name__ == \"__main__\" and 'get_ipython' not in globals():\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd2ec634",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated triple-quoted string literal (detected at line 304) (2905519407.py, line 291)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 291\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m\"\"\"if __name__ == \"__main__\":\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated triple-quoted string literal (detected at line 304)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "class LinearRegressionModel:\n",
    "    \"\"\"\n",
    "    A simple linear regression model implemented from scratch using gradient descent.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_features):\n",
    "        \"\"\"\n",
    "        Initialize the model with random weights and bias.\n",
    "        \n",
    "        Args:\n",
    "            n_features: Number of input features\n",
    "        \"\"\"\n",
    "        self.weights = np.random.randn(n_features, 1) * 0.01\n",
    "        self.bias = np.random.randn(1)\n",
    "        self.loss_history = []\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions using the linear model: y = Xw + b\n",
    "        \n",
    "        Args:\n",
    "            X: Input features (n_samples, n_features)\n",
    "            \n",
    "        Returns:\n",
    "            Predictions (n_samples, 1)\n",
    "        \"\"\"\n",
    "        return X.dot(self.weights) + self.bias\n",
    "    \n",
    "    def compute_loss(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Compute Mean Squared Error loss.\n",
    "        \n",
    "        Args:\n",
    "            y_true: True target values\n",
    "            y_pred: Predicted values\n",
    "            \n",
    "        Returns:\n",
    "            MSE loss value\n",
    "        \"\"\"\n",
    "        return np.mean((y_true - y_pred) ** 2)\n",
    "    \n",
    "    def train(self, X, y, learning_rate=0.01, epochs=200, verbose=True):\n",
    "        \"\"\"\n",
    "        Train the model using gradient descent.\n",
    "        \n",
    "        Args:\n",
    "            X: Training features (n_samples, n_features)\n",
    "            y: Target values (n_samples, 1)\n",
    "            learning_rate: Step size for gradient descent\n",
    "            epochs: Number of training iterations\n",
    "            verbose: Whether to print training progress\n",
    "            \n",
    "        Returns:\n",
    "            List of loss values for each epoch\n",
    "        \"\"\"\n",
    "        n_samples = len(y)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Forward pass\n",
    "            y_pred = self.predict(X)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = self.compute_loss(y, y_pred)\n",
    "            self.loss_history.append(loss)\n",
    "            \n",
    "            # Compute gradients\n",
    "            error = y - y_pred\n",
    "            grad_weights = -2 * X.T.dot(error) / n_samples\n",
    "            grad_bias = -2 * np.mean(error)\n",
    "            \n",
    "            # Update parameters\n",
    "            self.weights -= learning_rate * grad_weights\n",
    "            self.bias -= learning_rate * grad_bias\n",
    "            \n",
    "            # Print progress\n",
    "            if verbose and (epoch + 1) % 50 == 0:\n",
    "                print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss:.4f}\")\n",
    "        \n",
    "        return self.loss_history\n",
    "\n",
    "\n",
    "class HousingPricePredictor:\n",
    "    \"\"\"\n",
    "    Complete pipeline for housing price prediction including data preprocessing,\n",
    "    model training, and visualization.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, csv_path_or_df):\n",
    "        \"\"\"\n",
    "        Initialize the predictor with data from a CSV file or a pandas.DataFrame.\n",
    "\n",
    "        Args:\n",
    "            csv_path_or_df: Path to the housing dataset CSV file or a pandas.DataFrame\n",
    "        \"\"\"\n",
    "        import os\n",
    "        if isinstance(csv_path_or_df, pd.DataFrame):\n",
    "            # accept DataFrame directly (useful for notebooks/tests)\n",
    "            self.data = csv_path_or_df.copy()\n",
    "        else:\n",
    "            # validate path early and give a helpful error message\n",
    "            if not os.path.exists(csv_path_or_df):\n",
    "                raise FileNotFoundError(\n",
    "                    f\"{csv_path_or_df!r} not found. Provide a valid CSV path or a pandas.DataFrame.\"\n",
    "                )\n",
    "            self.data = pd.read_csv(csv_path_or_df)\n",
    "\n",
    "        self.model = None\n",
    "        self.scaler = StandardScaler()\n",
    "        self.X_scaled = None\n",
    "        self.y = None\n",
    "        \n",
    "    def preprocess_data(self):\n",
    "        \"\"\"\n",
    "        Preprocess the data: encode categorical variables and scale features.\n",
    "        \"\"\"\n",
    "        print(\"Preprocessing data...\")\n",
    "        \n",
    "        # Categorical columns to encode\n",
    "        categorical_columns = [\n",
    "            'mainroad', 'guestroom', 'basement', 'hotwaterheating',\n",
    "            'airconditioning', 'prefarea', 'furnishingstatus'\n",
    "        ]\n",
    "        \n",
    "        # Encode categorical variables\n",
    "        for col in categorical_columns:\n",
    "            label_encoder = LabelEncoder()\n",
    "            self.data[col] = label_encoder.fit_transform(self.data[col])\n",
    "        \n",
    "        # Separate features and target\n",
    "        self.X = self.data.drop(\"price\", axis=1).values.astype(float)\n",
    "        self.y = self.data[\"price\"].values.astype(float).reshape(-1, 1)\n",
    "        \n",
    "        # Scale features\n",
    "        self.X_scaled = self.scaler.fit_transform(self.X)\n",
    "        \n",
    "        print(f\"Data shape: {self.X_scaled.shape}\")\n",
    "        print(f\"Target shape: {self.y.shape}\")\n",
    "    \n",
    "    def train_model(self, learning_rate=0.01, epochs=200):\n",
    "        \"\"\"\n",
    "        Train the linear regression model.\n",
    "        \n",
    "        Args:\n",
    "            learning_rate: Learning rate for gradient descent\n",
    "            epochs: Number of training epochs\n",
    "        \"\"\"\n",
    "        print(f\"\\nTraining model for {epochs} epochs...\")\n",
    "        \n",
    "        self.model = LinearRegressionModel(n_features=self.X_scaled.shape[1])\n",
    "        self.model.train(\n",
    "            self.X_scaled, \n",
    "            self.y, \n",
    "            learning_rate=learning_rate, \n",
    "            epochs=epochs,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        print(\"Training completed!\")\n",
    "    \n",
    "    def evaluate_model(self):\n",
    "        \"\"\"\n",
    "        Evaluate the model and print performance metrics.\n",
    "        \"\"\"\n",
    "        y_pred = self.model.predict(self.X_scaled)\n",
    "        \n",
    "        mse = mean_squared_error(self.y, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(self.y, y_pred)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"MODEL EVALUATION\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"Mean Squared Error: {mse:,.2f}\")\n",
    "        print(f\"Root Mean Squared Error: {rmse:,.2f}\")\n",
    "        print(f\"RÂ² Score: {r2:.4f}\")\n",
    "        print(\"=\"*50)\n",
    "    \n",
    "    def plot_predictions(self):\n",
    "        \"\"\"\n",
    "        Plot predicted vs actual values with best fit line.\n",
    "        \"\"\"\n",
    "        y_pred = self.model.predict(self.X_scaled)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(self.y, y_pred, color='blue', alpha=0.5, label='Predictions')\n",
    "        \n",
    "        # Calculate and plot best fit line\n",
    "        coeffs = np.polyfit(self.y.ravel(), y_pred.ravel(), 1)\n",
    "        best_fit_line = coeffs[0] * self.y + coeffs[1]\n",
    "        plt.plot(self.y, best_fit_line, color='red', linewidth=2, label='Best Fit Line')\n",
    "        \n",
    "        # Perfect prediction line\n",
    "        plt.plot(self.y, self.y, color='green', linestyle='--', linewidth=1, label='Perfect Prediction')\n",
    "        \n",
    "        plt.xlabel(\"Actual Price\", fontsize=12)\n",
    "        plt.ylabel(\"Predicted Price\", fontsize=12)\n",
    "        plt.title(\"Housing Price Prediction: Actual vs Predicted\", fontsize=14, fontweight='bold')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_roc_curve(self):\n",
    "        \"\"\"\n",
    "        Plot ROC curve for binary classification (above/below median price).\n",
    "        \"\"\"\n",
    "        # Convert to binary classification problem\n",
    "        median_price = np.median(self.y)\n",
    "        y_binary = (self.y >= median_price).astype(int).ravel()\n",
    "        y_scores = self.model.predict(self.X_scaled).ravel()\n",
    "        \n",
    "        # Compute ROC curve and AUC\n",
    "        fpr, tpr, thresholds = roc_curve(y_binary, y_scores)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(fpr, tpr, color='darkorange', linewidth=2, \n",
    "                label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', linewidth=2, linestyle='--', \n",
    "                label='Random Classifier')\n",
    "        \n",
    "        plt.xlabel(\"False Positive Rate\", fontsize=12)\n",
    "        plt.ylabel(\"True Positive Rate\", fontsize=12)\n",
    "        plt.title(\"ROC Curve - Binary Classification (Above/Below Median Price)\", \n",
    "                 fontsize=14, fontweight='bold')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\nROC AUC Score: {roc_auc:.4f}\")\n",
    "    \n",
    "    def plot_loss_curve(self):\n",
    "        \"\"\"\n",
    "        Plot the training loss over epochs.\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(self.model.loss_history, color='blue', linewidth=2)\n",
    "        plt.xlabel(\"Epoch\", fontsize=12)\n",
    "        plt.ylabel(\"Mean Squared Error\", fontsize=12)\n",
    "        plt.title(\"Training Loss Over Epochs\", fontsize=14, fontweight='bold')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def run_complete_pipeline(self, learning_rate=0.01, epochs=200):\n",
    "        \"\"\"\n",
    "        Run the complete prediction pipeline from preprocessing to visualization.\n",
    "        \n",
    "        Args:\n",
    "            learning_rate: Learning rate for model training\n",
    "            epochs: Number of training epochs\n",
    "        \"\"\"\n",
    "        print(\"=\"*50)\n",
    "        print(\"HOUSING PRICE PREDICTION PIPELINE\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Step 1: Preprocess data\n",
    "        self.preprocess_data()\n",
    "        \n",
    "        # Step 2: Train model\n",
    "        self.train_model(learning_rate=learning_rate, epochs=epochs)\n",
    "        \n",
    "        # Step 3: Evaluate model\n",
    "def main(housing_csv=\"Housing.csv\"):\n",
    "        \n",
    "    Main execution function. Pass a path or a pandas.DataFrame.\n",
    "        print(\"\\nGenerating visualizations...\")\n",
    "    import os\n",
    "    if not os.path.exists(housing_csv):\n",
    "        raise FileNotFoundError(\n",
    "            f\"{housing_csv!r} not found. To run the demo place the CSV in the notebook folder \"\n",
    "            \"or call HousingPricePredictor with a pandas.DataFrame.\"\n",
    "        )\n",
    "\n",
    "    # Initialize predictor\n",
    "    predictor = HousingPricePredictor(housing_csv)\n",
    "\n",
    "\n",
    "    Main execution function.    main()\n",
    "\n",
    "    # Run complete pipeline\n",
    "    \"\"\"if __name__ == \"__main__\":\n",
    "\n",
    "    predictor.run_complete_pipeline(learning_rate=0.01, epochs=200)\n",
    "    # Initialize predictor\n",
    "\n",
    "\n",
    "    predictor = HousingPricePredictor(\"Housing.csv\")\n",
    "\n",
    "\n",
    "        main()\n",
    "\n",
    "# Prevent auto-execution inside interactive notebook kernels\n",
    "    # Run complete pipeline    predictor.run_complete_pipeline(learning_rate=0.01, epochs=200)\n",
    "if __name__ == \"__main__\" and 'get_ipython' not in globals():"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
