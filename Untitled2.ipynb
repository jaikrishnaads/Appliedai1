{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1ca3e98-64db-4c24-9864-ce9de8fe2d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FORWARD PASS ===\n",
      "Hidden1 input: [0.88, 0.79, 1.04]\n",
      "Hidden1 output: [0.88, 0.79, 1.04]\n",
      "Hidden2 input: [0.658, 1.029, 1.4]\n",
      "Hidden2 output: [0.658, 1.029, 1.4]\n",
      "Output input: 1.192\n",
      "Network output: 1.192\n",
      "Target output: 0.8\n",
      "Error: -0.392\n",
      "\n",
      "=== BACKWARD PASS ===\n",
      "Output delta: -0.392\n",
      "Hidden2 deltas: [-0.039, -0.078, -0.117]\n",
      "Hidden1 deltas: [-0.055, -0.078, -0.102]\n",
      "\n",
      "=== WEIGHT UPDATES ===\n",
      "\n",
      "=== FINAL RESULTS ===\n",
      "ORIGINAL WEIGHTS & BIASES:\n",
      "Input→Hidden1 weights: [[0.9, 0.2, 0.3], [0.2, 0.7, 0.4], [0.3, 0.1, 0.5]]\n",
      "Hidden1→Hidden2 weights: [[0.1, 0.2, 0.3], [0.2, 0.3, 0.4], [0.3, 0.4, 0.5]]\n",
      "Hidden2→Output weights: [0.1, 0.2, 0.3]\n",
      "Hidden1 biases: [0.1, 0.2, 0.3]\n",
      "Hidden2 biases: [0.1, 0.2, 0.3]\n",
      "Output bias: 0.5\n",
      "\n",
      "UPDATED WEIGHTS & BIASES:\n",
      "Input→Hidden1 weights: [[0.89, 0.18, 0.28], [0.18, 0.68, 0.37], [0.28, 0.07, 0.47]]\n",
      "Hidden1→Hidden2 weights: [[0.08, 0.17, 0.25], [0.19, 0.27, 0.36], [0.28, 0.36, 0.44]]\n",
      "Hidden2→Output weights: [-0.02, 0.01, 0.05]\n",
      "Hidden1 biases: [0.07, 0.16, 0.25]\n",
      "Hidden2 biases: [0.08, 0.16, 0.25]\n",
      "Output bias: 0.32\n",
      "\n",
      "Network Output: 1.192\n",
      "Target Output: 0.8\n",
      "Final Error: -0.392\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Neural Network Architecture: Input(3) -> Hidden1(3) -> Hidden2(3) -> Output(1)\n",
    "\n",
    "# Fixed initial weights and biases\n",
    "# Input to Hidden Layer 1 (3x3)\n",
    "w_input_hidden1 = [\n",
    "    [0.9, 0.2, 0.3],\n",
    "    [0.2, 0.7, 0.4],\n",
    "    [0.3, 0.1, 0.5]\n",
    "]\n",
    "\n",
    "# Hidden Layer 1 to Hidden Layer 2 (3x3)\n",
    "w_hidden1_hidden2 = [\n",
    "    [0.1, 0.2, 0.3],\n",
    "    [0.2, 0.3, 0.4],\n",
    "    [0.3, 0.4, 0.5]\n",
    "]\n",
    "\n",
    "# Hidden Layer 2 to Output (3x1)\n",
    "w_hidden2_output = [0.1, 0.2, 0.3]\n",
    "\n",
    "# Biases\n",
    "b_hidden1 = [0.1, 0.2, 0.3]\n",
    "b_hidden2 = [0.1, 0.2, 0.3]\n",
    "b_output = 0.5\n",
    "\n",
    "# Input values\n",
    "x = [0.5, 0.6, 0.7]\n",
    "y_target = 0.8\n",
    "learning_rate = 0.46\n",
    "\n",
    "# ReLU functions\n",
    "def relu(x):\n",
    "    return max(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return 1 if x > 0 else 0\n",
    "\n",
    "# Forward pass\n",
    "print(\"=== FORWARD PASS ===\")\n",
    "\n",
    "# Hidden Layer 1\n",
    "hidden1_in = [sum(w_input_hidden1[i][j] * x[i] for i in range(3)) + b_hidden1[j] for j in range(3)]\n",
    "hidden1_out = [relu(h) for h in hidden1_in]\n",
    "print(f\"Hidden1 input: {[round(h, 3) for h in hidden1_in]}\")\n",
    "print(f\"Hidden1 output: {[round(h, 3) for h in hidden1_out]}\")\n",
    "\n",
    "# Hidden Layer 2\n",
    "hidden2_in = [sum(w_hidden1_hidden2[i][j] * hidden1_out[i] for i in range(3)) + b_hidden2[j] for j in range(3)]\n",
    "hidden2_out = [relu(h) for h in hidden2_in]\n",
    "print(f\"Hidden2 input: {[round(h, 3) for h in hidden2_in]}\")\n",
    "print(f\"Hidden2 output: {[round(h, 3) for h in hidden2_out]}\")\n",
    "\n",
    "# Output\n",
    "output_in = sum(w_hidden2_output[j] * hidden2_out[j] for j in range(3)) + b_output\n",
    "output_out = relu(output_in)\n",
    "print(f\"Output input: {round(output_in, 3)}\")\n",
    "print(f\"Network output: {round(output_out, 3)}\")\n",
    "print(f\"Target output: {y_target}\")\n",
    "print(f\"Error: {round(y_target - output_out, 3)}\")\n",
    "\n",
    "# Backward pass\n",
    "print(\"\\n=== BACKWARD PASS ===\")\n",
    "\n",
    "# Output error\n",
    "output_error = y_target - output_out\n",
    "output_delta = output_error * relu_derivative(output_in)\n",
    "print(f\"Output delta: {round(output_delta, 3)}\")\n",
    "\n",
    "# Hidden Layer 2 error\n",
    "hidden2_error = [output_delta * w_hidden2_output[j] for j in range(3)]\n",
    "hidden2_delta = [hidden2_error[j] * relu_derivative(hidden2_in[j]) for j in range(3)]\n",
    "print(f\"Hidden2 deltas: {[round(h, 3) for h in hidden2_delta]}\")\n",
    "\n",
    "# Hidden Layer 1 error\n",
    "hidden1_error = [sum(hidden2_delta[j] * w_hidden1_hidden2[j][i] for j in range(3)) for i in range(3)]\n",
    "hidden1_delta = [hidden1_error[i] * relu_derivative(hidden1_in[i]) for i in range(3)]\n",
    "print(f\"Hidden1 deltas: {[round(h, 3) for h in hidden1_delta]}\")\n",
    "\n",
    "# Update weights and biases\n",
    "print(\"\\n=== WEIGHT UPDATES ===\")\n",
    "\n",
    "# Store original weights for comparison\n",
    "original_w_input_hidden1 = [row[:] for row in w_input_hidden1]\n",
    "original_w_hidden1_hidden2 = [row[:] for row in w_hidden1_hidden2]\n",
    "original_w_hidden2_output = w_hidden2_output[:]\n",
    "original_b_hidden1 = b_hidden1[:]\n",
    "original_b_hidden2 = b_hidden2[:]\n",
    "original_b_output = b_output\n",
    "\n",
    "# Hidden Layer 2 to Output\n",
    "w_hidden2_output = [w_hidden2_output[j] + learning_rate * output_delta * hidden2_out[j] for j in range(3)]\n",
    "b_output += learning_rate * output_delta\n",
    "\n",
    "# Hidden Layer 1 to Hidden Layer 2\n",
    "w_hidden1_hidden2 = [\n",
    "    [w_hidden1_hidden2[i][j] + learning_rate * hidden2_delta[j] * hidden1_out[i] for j in range(3)]\n",
    "    for i in range(3)\n",
    "]\n",
    "b_hidden2 = [b_hidden2[j] + learning_rate * hidden2_delta[j] for j in range(3)]\n",
    "\n",
    "# Input to Hidden Layer 1\n",
    "w_input_hidden1 = [\n",
    "    [w_input_hidden1[i][j] + learning_rate * hidden1_delta[j] * x[i] for j in range(3)]\n",
    "    for i in range(3)\n",
    "]\n",
    "b_hidden1 = [b_hidden1[j] + learning_rate * hidden1_delta[j] for j in range(3)]\n",
    "\n",
    "# Round to 2 decimal places\n",
    "w_input_hidden1 = [[round(w, 2) for w in row] for row in w_input_hidden1]\n",
    "w_hidden1_hidden2 = [[round(w, 2) for w in row] for row in w_hidden1_hidden2]\n",
    "w_hidden2_output = [round(w, 2) for w in w_hidden2_output]\n",
    "b_hidden1 = [round(b, 2) for b in b_hidden1]\n",
    "b_hidden2 = [round(b, 2) for b in b_hidden2]\n",
    "b_output = round(b_output, 2)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n=== FINAL RESULTS ===\")\n",
    "print(\"ORIGINAL WEIGHTS & BIASES:\")\n",
    "print(f\"Input→Hidden1 weights: {original_w_input_hidden1}\")\n",
    "print(f\"Hidden1→Hidden2 weights: {original_w_hidden1_hidden2}\")\n",
    "print(f\"Hidden2→Output weights: {original_w_hidden2_output}\")\n",
    "print(f\"Hidden1 biases: {original_b_hidden1}\")\n",
    "print(f\"Hidden2 biases: {original_b_hidden2}\")\n",
    "print(f\"Output bias: {original_b_output}\")\n",
    "\n",
    "print(\"\\nUPDATED WEIGHTS & BIASES:\")\n",
    "print(f\"Input→Hidden1 weights: {w_input_hidden1}\")\n",
    "print(f\"Hidden1→Hidden2 weights: {w_hidden1_hidden2}\")\n",
    "print(f\"Hidden2→Output weights: {w_hidden2_output}\")\n",
    "print(f\"Hidden1 biases: {b_hidden1}\")\n",
    "print(f\"Hidden2 biases: {b_hidden2}\")\n",
    "print(f\"Output bias: {b_output}\")\n",
    "\n",
    "print(f\"\\nNetwork Output: {round(output_out, 3)}\")\n",
    "print(f\"Target Output: {y_target}\")\n",
    "print(f\"Final Error: {round(y_target - output_out, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a34b02b-abaa-4123-bb66-13e6bb57aaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- INITIAL STATE (UNUPDATED) ---\n",
      "Hidden Layer Biases: [0.1, 0.1, 0.1, 0.1, 0.1]\n",
      "Output Layer Bias: 0.1\n",
      "Sample Weights (Input[0] to Hidden): [0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Weights (Hidden to Output): [0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "\n",
      "\n",
      "--- UPDATED STATE (AFTER 1 ITERATION) ---\n",
      "Hidden Layer Biases: [2.93, 2.93, 2.93, 2.93, 2.93]\n",
      "Output Layer Bias: -1.28\n",
      "Sample Weights (Input[0] to Hidden): [3.33, 3.33, 3.33, 3.33, 3.33]\n",
      "Weights (Hidden to Output): [-2.05, -2.05, -2.05, -2.05, -2.05]\n",
      "\n",
      "\n",
      "Final Prediction was: 4.72\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "LR = 0.8 # Learning Rate\n",
    "TARGET = 3.0  # The value we want the network to predict\n",
    "X = [1.0, 0.5, 2.0]  # Inputs x1, x2, x3\n",
    "\n",
    "# 1. Initialize Weights and Biases (No random lib)\n",
    "# Weights from Input (3) to Hidden (5) - 15 total\n",
    "w_input_hidden = [[0.5 for _ in range(5)] for _ in range(3)]\n",
    "# Biases for Hidden Layer (5)\n",
    "b_hidden = [0.1 for _ in range(5)]\n",
    "\n",
    "# Weights from Hidden (5) to Output (1) - 5 total\n",
    "w_hidden_output = [0.5 for _ in range(5)]\n",
    "# Bias for Output Layer (1)\n",
    "b_output = 0.1\n",
    "\n",
    "\n",
    "def show_state(label):\n",
    "    print(f\"--- {label} ---\")\n",
    "    print(f\"Hidden Layer Biases: {[round(b, 2) for b in b_hidden]}\")\n",
    "    print(f\"Output Layer Bias: {round(b_output, 2)}\")\n",
    "    print(\"Sample Weights (Input[0] to Hidden):\", [round(w_input_hidden[0][i], 2) for i in range(5)])\n",
    "    print(\"Weights (Hidden to Output):\", [round(w, 2) for w in w_hidden_output])\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Show Initial State\n",
    "show_state(\"INITIAL STATE (UNUPDATED)\")\n",
    "\n",
    "# --- FORWARD PASS ---\n",
    "# Calculate Hidden Layer Neurons (x4 to x8)\n",
    "# Note: Using a simple linear activation for clarity\n",
    "hidden_outputs = []\n",
    "for j in range(5):\n",
    "    neuron_sum = b_hidden[j]\n",
    "    for i in range(3):\n",
    "        neuron_sum += X[i] * w_input_hidden[i][j]\n",
    "    hidden_outputs.append(neuron_sum)\n",
    "\n",
    "# Calculate Output Neuron (x10)\n",
    "output = b_output\n",
    "for j in range(5):\n",
    "    output += hidden_outputs[j] * w_hidden_output[j]\n",
    "\n",
    "# --- BACKWARD PASS (Manual Update) ---\n",
    "# 1. Calculate Error (Target - Prediction)\n",
    "error = TARGET - output\n",
    "\n",
    "# 2. Update Output Weights and Bias\n",
    "# Gradient for output weights = error * hidden_output\n",
    "for j in range(5):\n",
    "    delta_w_out = error * hidden_outputs[j]\n",
    "    w_hidden_output[j] += LR * delta_w_out\n",
    "\n",
    "b_output += LR * error\n",
    "\n",
    "# 3. Update Input-to-Hidden Weights and Biases\n",
    "# Gradient for hidden = error * weight_to_output * input\n",
    "for j in range(5):\n",
    "    # Backpropagate error through the output weight\n",
    "    hidden_error = error * w_hidden_output[j]\n",
    "    \n",
    "    for i in range(3):\n",
    "        w_input_hidden[i][j] += LR * hidden_error * X[i]\n",
    "    \n",
    "    b_hidden[j] += LR * hidden_error\n",
    "\n",
    "# Show Final State\n",
    "show_state(\"UPDATED STATE (AFTER 1 ITERATION)\")\n",
    "def show_state(label):\n",
    "    print(f\"--- {label} ---\")\n",
    "    print(f\"Hidden Layer Biases: {[round(b, 2) for b in b_hidden]}\")\n",
    "    print(f\"Output Layer Bias: {round(b_output, 2)}\")\n",
    "    print(\"Sample Weights (Input[0] to Hidden):\", [round(w_input_hidden[0][i], 2) for i in range(5)])\n",
    "    print(\"Weights (Hidden to Output):\", [round(w, 2) for w in w_hidden_output])\n",
    "    print(\"\\n\")\n",
    "print(f\"Final Prediction was: {round(output, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36178eae-ba86-4cee-98da-12dba7339984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FORWARD PASS ===\n",
      "Hidden1 input: [0.88, 0.79, 1.04]\n",
      "Hidden1 output: [0.706, 0.658, 0.778]\n",
      "Hidden2 input: [0.536, 0.85, 1.164]\n",
      "Hidden2 output: [0.49, 0.691, 0.822]\n",
      "Output input: 0.934\n",
      "Network output: 0.732\n",
      "Target output: 0.8\n",
      "Error: 0.068\n",
      "\n",
      "=== BACKWARD PASS ===\n",
      "Output delta: 0.031\n",
      "Hidden2 deltas: [0.002, 0.003, 0.003]\n",
      "Hidden1 deltas: [0.001, 0.002, 0.001]\n",
      "\n",
      "=== WEIGHT UPDATES ===\n",
      "\n",
      "=== FINAL RESULTS ===\n",
      "ORIGINAL WEIGHTS & BIASES:\n",
      "Input→Hidden1 weights: [[0.9, 0.2, 0.3], [0.2, 0.7, 0.4], [0.3, 0.1, 0.5]]\n",
      "Hidden1→Hidden2 weights: [[0.1, 0.2, 0.3], [0.2, 0.3, 0.4], [0.3, 0.4, 0.5]]\n",
      "Hidden2→Output weights: [0.1, 0.2, 0.3]\n",
      "Hidden1 biases: [0.1, 0.2, 0.3]\n",
      "Hidden2 biases: [0.1, 0.2, 0.3]\n",
      "Output bias: 0.5\n",
      "\n",
      "UPDATED WEIGHTS & BIASES:\n",
      "Input→Hidden1 weights: [[0.9, 0.2, 0.3], [0.2, 0.7, 0.4], [0.3, 0.1, 0.5]]\n",
      "Hidden1→Hidden2 weights: [[0.1, 0.2, 0.3], [0.2, 0.3, 0.4], [0.3, 0.4, 0.5]]\n",
      "Hidden2→Output weights: [0.11, 0.21, 0.31]\n",
      "Hidden1 biases: [0.1, 0.2, 0.3]\n",
      "Hidden2 biases: [0.1, 0.2, 0.3]\n",
      "Output bias: 0.51\n",
      "\n",
      "Network Output: 0.732\n",
      "Target Output: 0.8\n",
      "Final Error: 0.068\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Neural Network Architecture: Input(3) -> Hidden1(3) -> Hidden2(3) -> Output(1)\n",
    "\n",
    "# Fixed initial weights and biases\n",
    "# Input to Hidden Layer 1 (3x3)\n",
    "w_input_hidden1 = [\n",
    "    [0.9, 0.2, 0.3],\n",
    "    [0.2, 0.7, 0.4],\n",
    "    [0.3, 0.1, 0.5]\n",
    "]\n",
    "\n",
    "# Hidden Layer 1 to Hidden Layer 2 (3x3)\n",
    "w_hidden1_hidden2 = [\n",
    "    [0.1, 0.2, 0.3],\n",
    "    [0.2, 0.3, 0.4],\n",
    "    [0.3, 0.4, 0.5]\n",
    "]\n",
    "\n",
    "# Hidden Layer 2 to Output (3x1)\n",
    "w_hidden2_output = [0.1, 0.2, 0.3]\n",
    "\n",
    "# Biases\n",
    "b_hidden1 = [0.1, 0.2, 0.3]\n",
    "b_hidden2 = [0.1, 0.2, 0.3]\n",
    "b_output = 0.5\n",
    "\n",
    "# Input values\n",
    "x = [0.5, 0.6, 0.7]\n",
    "y_target = 0.8\n",
    "learning_rate = 0.46\n",
    "\n",
    "# Tanh functions\n",
    "def tanh(x):\n",
    "    return math.tanh(x)\n",
    "\n",
    "def tanh_derivative(x):\n",
    "    return 1 - math.tanh(x)**2\n",
    "\n",
    "# Forward pass\n",
    "print(\"=== FORWARD PASS ===\")\n",
    "\n",
    "# Hidden Layer 1\n",
    "hidden1_in = [sum(w_input_hidden1[i][j] * x[i] for i in range(3)) + b_hidden1[j] for j in range(3)]\n",
    "hidden1_out = [tanh(h) for h in hidden1_in]\n",
    "print(f\"Hidden1 input: {[round(h, 3) for h in hidden1_in]}\")\n",
    "print(f\"Hidden1 output: {[round(h, 3) for h in hidden1_out]}\")\n",
    "\n",
    "# Hidden Layer 2\n",
    "hidden2_in = [sum(w_hidden1_hidden2[i][j] * hidden1_out[i] for i in range(3)) + b_hidden2[j] for j in range(3)]\n",
    "hidden2_out = [tanh(h) for h in hidden2_in]\n",
    "print(f\"Hidden2 input: {[round(h, 3) for h in hidden2_in]}\")\n",
    "print(f\"Hidden2 output: {[round(h, 3) for h in hidden2_out]}\")\n",
    "\n",
    "# Output\n",
    "output_in = sum(w_hidden2_output[j] * hidden2_out[j] for j in range(3)) + b_output\n",
    "output_out = tanh(output_in)\n",
    "print(f\"Output input: {round(output_in, 3)}\")\n",
    "print(f\"Network output: {round(output_out, 3)}\")\n",
    "print(f\"Target output: {y_target}\")\n",
    "print(f\"Error: {round(y_target - output_out, 3)}\")\n",
    "\n",
    "# Backward pass\n",
    "print(\"\\n=== BACKWARD PASS ===\")\n",
    "\n",
    "# Output error\n",
    "output_error = y_target - output_out\n",
    "output_delta = output_error * tanh_derivative(output_in)\n",
    "print(f\"Output delta: {round(output_delta, 3)}\")\n",
    "\n",
    "# Hidden Layer 2 error\n",
    "hidden2_error = [output_delta * w_hidden2_output[j] for j in range(3)]\n",
    "hidden2_delta = [hidden2_error[j] * tanh_derivative(hidden2_in[j]) for j in range(3)]\n",
    "print(f\"Hidden2 deltas: {[round(h, 3) for h in hidden2_delta]}\")\n",
    "\n",
    "# Hidden Layer 1 error\n",
    "hidden1_error = [sum(hidden2_delta[j] * w_hidden1_hidden2[j][i] for j in range(3)) for i in range(3)]\n",
    "hidden1_delta = [hidden1_error[i] * tanh_derivative(hidden1_in[i]) for i in range(3)]\n",
    "print(f\"Hidden1 deltas: {[round(h, 3) for h in hidden1_delta]}\")\n",
    "\n",
    "# Update weights and biases\n",
    "print(\"\\n=== WEIGHT UPDATES ===\")\n",
    "\n",
    "# Store original weights for comparison\n",
    "original_w_input_hidden1 = [row[:] for row in w_input_hidden1]\n",
    "original_w_hidden1_hidden2 = [row[:] for row in w_hidden1_hidden2]\n",
    "original_w_hidden2_output = w_hidden2_output[:]\n",
    "original_b_hidden1 = b_hidden1[:]\n",
    "original_b_hidden2 = b_hidden2[:]\n",
    "original_b_output = b_output\n",
    "\n",
    "# Hidden Layer 2 to Output\n",
    "w_hidden2_output = [w_hidden2_output[j] + learning_rate * output_delta * hidden2_out[j] for j in range(3)]\n",
    "b_output += learning_rate * output_delta\n",
    "\n",
    "# Hidden Layer 1 to Hidden Layer 2\n",
    "w_hidden1_hidden2 = [\n",
    "    [w_hidden1_hidden2[i][j] + learning_rate * hidden2_delta[j] * hidden1_out[i] for j in range(3)]\n",
    "    for i in range(3)\n",
    "]\n",
    "b_hidden2 = [b_hidden2[j] + learning_rate * hidden2_delta[j] for j in range(3)]\n",
    "\n",
    "# Input to Hidden Layer 1\n",
    "w_input_hidden1 = [\n",
    "    [w_input_hidden1[i][j] + learning_rate * hidden1_delta[j] * x[i] for j in range(3)]\n",
    "    for i in range(3)\n",
    "]\n",
    "b_hidden1 = [b_hidden1[j] + learning_rate * hidden1_delta[j] for j in range(3)]\n",
    "\n",
    "# Round to 2 decimal places\n",
    "w_input_hidden1 = [[round(w, 2) for w in row] for row in w_input_hidden1]\n",
    "w_hidden1_hidden2 = [[round(w, 2) for w in row] for row in w_hidden1_hidden2]\n",
    "w_hidden2_output = [round(w, 2) for w in w_hidden2_output]\n",
    "b_hidden1 = [round(b, 2) for b in b_hidden1]\n",
    "b_hidden2 = [round(b, 2) for b in b_hidden2]\n",
    "b_output = round(b_output, 2)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n=== FINAL RESULTS ===\")\n",
    "print(\"ORIGINAL WEIGHTS & BIASES:\")\n",
    "print(f\"Input→Hidden1 weights: {original_w_input_hidden1}\")\n",
    "print(f\"Hidden1→Hidden2 weights: {original_w_hidden1_hidden2}\")\n",
    "print(f\"Hidden2→Output weights: {original_w_hidden2_output}\")\n",
    "print(f\"Hidden1 biases: {original_b_hidden1}\")\n",
    "print(f\"Hidden2 biases: {original_b_hidden2}\")\n",
    "print(f\"Output bias: {original_b_output}\")\n",
    "\n",
    "print(\"\\nUPDATED WEIGHTS & BIASES:\")\n",
    "print(f\"Input→Hidden1 weights: {w_input_hidden1}\")\n",
    "print(f\"Hidden1→Hidden2 weights: {w_hidden1_hidden2}\")\n",
    "print(f\"Hidden2→Output weights: {w_hidden2_output}\")\n",
    "print(f\"Hidden1 biases: {b_hidden1}\")\n",
    "print(f\"Hidden2 biases: {b_hidden2}\")\n",
    "print(f\"Output bias: {b_output}\")\n",
    "\n",
    "print(f\"\\nNetwork Output: {round(output_out, 3)}\")\n",
    "print(f\"Target Output: {y_target}\")\n",
    "print(f\"Final Error: {round(y_target - output_out, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afffa2d-f6cf-4ba2-8658-15753beb04b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
